<html>

<head>
    <style>
        body {
            /*margin-left: 18%;*/
            /*margin-right: 18%;*/
        }

        img {
          background-color: green;
          /*float: left;*/

      }

      h1 {
          text-align: left;
      }

      p {
          font-size: 20px;
      }
      .container{
        background-color:white;
        width:62%;
        height:auto;
        margin:auto;
    }
    .row{
        /*width:auto;*/
        height:auto;
        display: flex;
        /*background-color:white;*/
    }
    .info{
        margin-left:20px;
        margin-top:20px;
        margin-right:20px;

        /*background-color:#EEE;*/
        height:auto;
    }
    .sysulogo{
        background-color:green;
        padding:12px 12px 12px 12px;
    }
    .sysubot{
        background-color:green;
    }
    .avatar{
        margin-top:20px;
        margin-bottom:10px;
        width: 201px;
        flex:row;
        /*background-color:#EEE;*/
        height:auto;
    }
    .elem{
        margin-top:10px;
        margin-bottom:10px;

        flex:row;
        /*background-color:#EEE;*/
        height:auto;
    }
    .button {
      background-color: green; /* Green */
      border: none;
      color: white;
      /*padding: 15px 32px;*/
      text-align: center;
      text-decoration: none;
      display: inline-block;
      /*font-size: 16px;*/
      margin: 4px 2px;
      cursor: pointer;
    }

</style>
<script>
function showOrHide(bt)
    {
        var id = bt.id.concat("_info");
        if(document.getElementById(id).style.height == "0px")
            document.getElementById(id).style = "height: auto;overflow:hidden"
        else
            document.getElementById(id).style.height = "0px";
    }
</script>

<title>万海 主页</title>
<meta content="text/html; charset=unicode" http-equiv="Content-Type">
</head>



<body>
    <div class="container">
        <div class="sysulogo">
            <img src="image/logo.png">
        </div>
        <hr>
        <div class="row">

            <div class="elem">
                [<a href="index.html">首页</a>]
                [<a href="research.html">研究方向</a>]
                [<a href="pub.html">著作论文</a>]
                [<a href="project.html">科研项目</a>]
                [<a href="teaching.html">讲授课程</a>]
                [<a href="seminar.html">研讨班</a>]
            </div>
</div>
                <hr>
        <div class="row">
            <div class="elem">
                    <h2>研讨班记录</h2>
                项目组每周组织研讨班，就最新的科研议题和经典论文进行报告和讨论。
                    <ul>

                        <h3>2019 Spring</h3>
<li>May 6th, 2019 (Monday)<button class="button" id="show562019" onclick="showOrHide(this)">...</button>
<div class=".elem" id="show562019_info" style="height:0;overflow:hidden">
Time: 14:00 PM – 17:00 PM<br/>
Location: Room A319, School of Data and Computer Science, East Campus, SYSU<br/>
<br/>
Topic: CoAFTA: An Efficient SAT-Based Tool for Computing Minimal Cut Sets of Coherent and Non-Coherent Fault Trees<br/>
Reporter: 罗炜麟<br/>
Abstract: Fault tree analysis (FTA), widely used in safety-critical systems, is a prominent reliability analysis method. Computing minimal cut sets (MCSs), i.e., finding all the combination with fewest basic events that result in the top event, plays a fundamental role in FTA. Classical methods still have limitations for the inherent intractability of fault trees. Thanks to the progress on satisfiability (SAT) problem, Luo and Wei introduced the SAT technique into computing MCSs. However, it is limited to hold coherent fault trees and weakly combined with a SAT solver. In this paper, we propose a SAT-based tool -- CoAFTA with an iterative framework to search all MCSs of coherent/non-coherent fault trees. Motivated by the conflict analysis and backjumping methods in SAT, the computation of MCSs is embedded in the CDCL that is a famous framework in SAT. Specifically, given a fault tree, we iteratively search for a cut set based on the CDCL. Based on the unit propagation, we provide a breadth-first search algorithm to efficiently extract MCS from the cut set. After that, we simulate the conflict analysis and backjumping process to start a new iteration. The experimental results show that CoAFTA outperforms state-of-the-art tools. Especially, CoAFTA consumes about one order of magnitude less memory usage.<br/>
Reference:<br/>
[1] Antoine Rauzy: Mathematical foundations of minimal cutsets. IEEE Trans. Reliability 50(4): 389-396 (2001)<br/>
<br/>
Topic: LOGION: A Local Search Algorithm for Goal-Conflict Identification<br/>
Reporter: 钟洪桢<br/>
Abstract: Goal-conﬂict analysis has been widely used as an abstraction for risk analysis in goal-oriented requirements engineering approaches. In this context, where the expected behaviour of the system-to-be is captured in terms of domain properties and goals, identifying combinations of circumstances that may make the goals diverge, i.e., not to be satisfed as a whole, is of most importance. It is important that generating general and large number of boundary conditions. However, the previous approaches only capture some specific goal expressions, or few of them. In this paper, we present a novel automated approach to identify boundary conditions, using local search. More precisely, we develop a local search that, given the LTL formulation of the domain properties and the goals, it searches for formulae that capture divergences in the specification, and uses a tabu memory to avoid repeatedly revisiting the some formulae. We exploit two-level fitness function to successfully guide our local search to the general solutions. We assess our technique on a set of case studies, and show that our local search is able to produce the number of unique boundary conditions orders of magnitude larger than state-of-the-art, and can find more general boundary conditions.<br/>
Reference:<br/>
<br/>
Topic: Image Generation from Scene Graphs<br/>
Reporter: 陈海城<br/>
Abstract: To truly understand the visual world our models should be able not only to recognize images but also generate them. To this end, there has been exciting recent progress on generating images from natural language descriptions. These methods give stunning results on limited domains such as descriptions of birds or flowers, but struggle to faithfully reproduce complex sentences with many objects and relationships. To overcome this limitation the paper proposes a method for generating images from scene graphs, enabling explicitly reasoning about objects and their relationships. Its model uses graph convolution to process input graphs, computes a scene layout by predicting bounding boxes and segmentation masks for objects, and converts the layout to an image with a cascaded refinement network. The network is trained adversarially against a pair of discriminators to ensure realistic outputs. They validate our approach on Visual Genome and COCO-Stuff, where qualitative results, ablations, and user studies demonstrate our method’s ability to generate complex images with multiple objects.<br/>
Reference:<br/>
[1] Justin Johnson: Image Generation from Scene Graphs. CVPR 2018: 1219-1228<br/></div></li>

<li>April 29nd, 2019 (Monday)<button class="button" id="show4292019" onclick="showOrHide(this)">...</button>
<div class=".elem" id="show4292019_info" style="height:0;overflow:hidden">
Time: 14:00 PM – 17:00 PM<br/>
Location: Room A319, School of Data and Computer Science, East Campus, SYSU<br/>
<br/>
Topic: Automatic Verification of Liveness Properties in the Situation Calculus<br/>
Reporter: 李健<br/>
Abstract: In dynamic systems, liveness properties concern whether something good will eventually happen. Examples of liveness properties are termination of programs and goal achievability. In this paper, we consider the following theorem-proving problem: given an action theory and a goal, check whether the goal is achievable in every model of the action theory. We propose to use mathematical induction to address this problem: we identify a natural number feature and prove by mathematical induction that for any values of the feature, the goal is achievable. Both the basis and induction steps are verified using first-order theorem provers. We propose a simple method to identify potential features which are the number of objects satisfying a certain formula by generating small models of the action theory and calling a classical planner to achieve the goal. We also propose to regress the goal via different actions and then verify whether the resulting goals are achievable. We implemented the proposed method and experimented with the blocks world domain and a number of other domains from the literature. Experimental results showed that most goals can be verified within a reasonable amount of time.<br/>
Reference:<br/>
<br/>
Topic: Abstraction via Forgetting in the Situation Calculus<br/>
Reporter: 林子莨<br/>
Abstract: The idea of abstraction is widely applied in artificial intelligence. Recently, a theoretical agent abstraction framework based on the situation calculus was proposed, where abstraction is defined as a bi-simulation relation between the models of a high-level action theory and a low-level action theory. In this paper, we correlate this framework with forgetting, an important method to remove unimportant details in logic. First, we present a general method to compute an abstraction via forgetting given a low-level action theory and a refinement mapping. Second, we implement this method under propositional cases and experiments show that it can effectively accelerate domain-independent planning.<br/>
Reference:<br/>
<br/>
Topic: Generality in Artificial Intelligence<br/>
Reporter: 董煜<br/>
Abstract: Each problem in WSC has a scene, and for most problems, the scenes are different, which can cover a wide range of daily life. In different scene, the system must all be applicable. Thus, the system needs generality. However, AI programs suffered from a lack of generality, causing two symptoms. First is that a small addition to the idea of a program often involves a complete rewrite. Second is that no one knows how to make a general commonsense knowledge database. In this meeting, I shall report Generality in Artificial Intelligence, John McCarthy's paper in 1987, which is about several ideas for achieving generality; and another paper which is related to this content.<br/>
Reference:<br/>
[1] John McCarthy: Notes on Formalizing Context. IJCAI 1993: 555-562<br/>
[2] John McCarthy: Generality in Artificial Intelligence. Commun. ACM 30(12): 1029-1035 (1987)<br/></div></li>

<li>April 22nd, 2019 (Monday)<button class="button" id="show4222019" onclick="showOrHide(this)">...</button>
<div class=".elem" id="show4222019_info" style="height:0;overflow:hidden">
Time: 14:00 PM – 17:00 PM<br/>
Location: Room A319, School of Data and Computer Science, East Campus, SYSU<br/>
<br/>
Topic: The Hanabi Challenge: A New Frontier for AI Research<br/>
Reporter: 方弼清<br/>
Abstract: From the early days of computing, games have been important testbeds for studying how well machines can do sophisticated decision making. In recent years, machine learning has made dramatic advances with artificial agents reaching superhuman performance in challenge domains like Go, Atari, and some variants of poker. As with their predecessors of chess, checkers, and backgammon, these game domains have driven research by providing sophisticated yet well-defined challenges for artificial intelligence practitioners. We continue this tradition by proposing the game of Hanabi as a new challenge domain with novel problems that arise from its combination of purely cooperative gameplay and imperfect information in a two to five player setting. In particular, we argue that Hanabi elevates reasoning about the beliefs and intentions of other agents to the foreground. We believe developing novel techniques capable of imbuing artificial agents with such theory of mind will not only be crucial for their success in Hanabi, but also in broader collaborative efforts, and especially those with human partners. To facilitate future research, we introduce the open-source Hanabi Learning Environment, propose an experimental framework for the research community to evaluate algorithmic advances, and assess the performance of current state-of-the-art techniques.<br/>
Reference:<br/>
[1] Bard, N., Foerster, J.N., Chandar, S., Burch, N., Lanctot, M., Song, H.F., Parisotto, E., Dumoulin, V., Moitra, S., Hughes, E. and Dunning, I., 2019. The Hanabi Challenge: A New Frontier for AI Research. arXiv preprint arXiv:1902.00506.<br/>
<br/>
Topic: Scene Graph Completion with Image Descriptions and Refinement<br/>
Reporter: 夏勇涛<br/>
Abstract: Scene graph which can be seen as a set of visual triples has been proved to benefit many computer vision and ar- tificial intelligence applications. Generating scene graph, a time-consuming and difficult job, has attracted increas- ing attention. Previous methods concentrate on only us- ing the scene graph structural or visual information to gen- erate or complete scene graph and overlook visual triples prediction accuracy. In fact, there are image descriptions with rich semantic information, e.g., the Visual Genome (VG) dataset. In this paper, we propose a novel Descrip- tion Scene Graph Representation Learning model (DSRL) to take advantages of image descriptions to learn better rep- resentations of scene graphs. And when we have more accu- rate visual triple representations, we can use commonsense knowledge to refine the scene graph. More specifically, we explore two encoders, including BiLSTM and Trans- former to encode semantics of image descriptions and vi- sual triples. We further use both visual triples and image de- scriptions to help the representation learning through sim- ilarity module and aggregation module. At last, we refine the scene graph through integer linear programming(ILP). This is the first attempt that uses image descriptions in rep- resentation learning of scene graphs. We use scene graph completion tasks to verify our model. Experimental re- sults demonstrate that DSRL outperforms all baselines in two tasks: link prediction and visual triple classification, which justifies the significance of combining image descrip- tions and visual triple for representation learning of scene graphs.<br/>
Reference:<br/>
<br/>
Topic: Understanding Social relationship with Person-pair Relations<br/>
Reporter: 李雷来<br/>
Abstract: This paper focuses on social relationships understanding which aims at inferring the social relations among people in a given scene. Relationship Understanding has attracted increasing attention in computer vision recently. Great progress has been made since the rise of deep learning. However, previous works mainly improves the results by mining the basic features of person pair or introducing prior knowledge of object and relationship co-occurrence frequencies, without taking into account the interaction of different pairs. It is natural to consider these interaction cues, {\it i.e.,} the mutual influence of multiple person pairs, in social relationship understanding. For instance, if two person pairs in an image are ``Friends'', then the third pair is always ``Friends'' or at least other similar relations but not ``No Relation''. Therefore, to capture these interaction cues, we propose the concept of social relationship graph, and a novel end-to-end trainable Person-Pair Relation Network ({\it PPRN}) using standard RNNs, a inference network that learns iteratively to improve its predictions via message passing among person pair nodes.<br/>
In PPRN model, we provide a message passing and message pooling module to implements the message passing between various person pairs，achieving the purpose of the mutual restraint between different person pair, and we also implements a attention module to combine the contextual object feature. In this process, the first step is to iterate the two modules of message passing and pooling between person pair's relationships, and then combine the image features of object bounding box generated by the region proposal network, and finally optimization.<br/>
In the experiments, we evaluate our model in two large-scale datasets, and the two datasets contain three relational granularity, and further analyze by case studies. Experimental results demonstrate that our model outperforms baselines, which justifies the significance of considering the interaction between various person pairs in social relationship understanding.<br/>
Reference:<br/></div></li>

<li>April 15th, 2019 (Monday)<button class="button" id="show4152019" onclick="showOrHide(this)">...</button>
<div class=".elem" id="show4152019_info" style="height:0;overflow:hidden">
Time: 14:00 PM – 17:00 PM<br/>
Location: Room A319, School of Data and Computer Science, East Campus, SYSU<br/>
<br/>
Topic: Iterated Games with LDL Goals over Finite Traces<br/>
Reporter: 刘昭帅<br/>
Abstract: This paper first defines iterated Boolean games with LDL_f goals over finite traces (iBG_f), instead of PL or LTL formulae as in conventional games (BG) or iterated Boolean games (iBG), and then investigate its main game-theoretic properties using a new automata-theoretic approach to reason about Nash equilibria. By using this automata-theoretic technique this paper shows a number of verification and characterisation results in iBG_f: First, deciding whether a strategy profile is a Nash equilibrium can be solved in PSPACE-complete, no harder than LDL_f satisfiability. Second, deciding whether an iBG_f has a Nash equilibrium can be solved in 2EXPTIME, no harder than solving LDL_f synthesis. Third, deciding whether an LDL_f formula is satisfied by some or every Nash equilibrium of an iBG_f can be solved in 2EXPTIME. Last but not least, there are several complexity results for the main decision problems related to the equilibrium analysis with respect to extensions and restrictions of iBG_f (i.e. games with QPLDL_f goals, memoryless strategies and myopic strategies).<br/>
Reference:<br/>
[1] Julian Gutierrez, Giuseppe Perelli, Michael Wooldridge: Iterated Games with LDL Goals over Finite Traces. AAMAS 2017: 696-704<br/>
<br/>
Topic: Abstraction via Forgetting in the Situation Calculus Action Theories: A New Result<br/>
Reporter: 罗凯伦<br/>
Abstract: The abstraction framework contains three parts: a low-level action theory, a high-level action theory and a refinement mapping between these two theories. In this talk, we discuss the existential problem of a high-level action theory when a low-level theory and a refinement mapping are given. First, we regard an abstraction as a partition over a set of low-level situations using a abstraction relation.  We then show that a correct abstraction (high-level action theory) exists iff all situations in the same equivalent class have the same executablility and effects of update.<br/>
Reference:<br/></div></li>

<li>April 8th, 2019 (Monday)<button class="button" id="show482019" onclick="showOrHide(this)">...</button>
<div class=".elem" id="show482019_info" style="height:0;overflow:hidden">
Time: 14:00 PM – 17:00 PM<br/>
Location: Room A319, School of Data and Computer Science, East Campus, SYSU<br/>
<br/>
Topic: Goal-Conflict Detection<br/>
Reporter: 钟洪桢<br/>
Abstract: Goal-conﬂict analysis has been widely used as an abstraction for risk analysis in goal-oriented requirements engineering approaches. In this context, where the expected behaviour of the system-to-be is captured in terms of domain properties and goals, identifying combinations of circumstances that may make the goals diverge, i.e., not to be satisfed as a whole, is of most importance. Various approaches have been proposed in order to automatically identify boundary conditions, i.e., formulas capturing goal-divergent situations, but they either apply only to some specifc goal expressions, or are aﬀected by scalability issues that make them applicable only to relatively small specifcations. In this paper, we present a novel approach to automatically identify boundary conditions, using evolutionary computation. More precisely, we develop a genetic algorithm that, given the LTL formulation of the domain properties and the goals, it searches for formulas that capture divergences in the specifcation. We exploit a modern LTL satisfability checker to successfully guide our genetic algorithm to the solutions. We assess our technique on a set of case studies, and show that our genetic algorithm is able to fnd boundary conditions that cannot be generated by related approaches, and is able to efciently scale to LTL specifcations that other approaches are unable to deal with.<br/>
Reference:<br/>
[1] Renzo Degiovanni, Nicolás Ricci, Dalal Alrajeh, Pablo F. Castro, Nazareno Aguirre. Goal-conflict detection based on temporal satisfiability checking. ASE 2016: 507-518<br/>
[2] Renzo Degiovanni, Facundo Molina, Germán Regis, Nazareno Aguirre. A genetic algorithm for goal-conflict identification. ASE 2018: 520-531<br/>
<br/>
Topic: Scene Graph Refinement<br/>
Reporter: 罗宇舟<br/>
Abstract: scene graph refinement which aims at refining the scene graph generated by existing scene graph generation models, most of which are data-driven fashion. These models often take Recall@50 and Recall@100 as evaluation metrics, which is inclined to overlook visual triples prediction accuracy. To deal with the problem, we propose a method that introduces commonsense knowledge as post-processing to refine the generated scene graph. We first formulate the scene graph refinement task as an integer linear programming (ILP) problem with the objective function generated from existing models and the constraints, commonsense knowledge which are represented by rules. Then we further utilize the bounding boxes of location information in each visual triple to optimize our method. Experimental results on two datasets, VRD and VG, demonstrate that our approach outperforms baseline methods in two typical classification tasks, which can prove the significance of our approach.<br/>
Reference:<br/>
[1] Xu D, Zhu Y, Choy C B, et al. Scene Graph Generation by Iterative Message Passing. CVPR 2017: 3097–3106.<br/>
[2] Liang K, Guo Y, Chang H, et al. Visual Relationship Detection With Deep Structural Ranking. AAAI 2018: 7098-7105<br/>
[3] Wang Q, Wang B, Guo L. Knowledge Base Completion Using Embeddings and Rules. IJCAI 2015: 1859–1866.<br/></div></li>

<li>March 25th, 2019 (Monday)<button class="button" id="show3252019" onclick="showOrHide(this)">...</button>
<div class=".elem" id="show3252019_info" style="height:0;overflow:hidden">
Time: 14:00 PM – 17:00 PM<br/>
Location: Room 607, School of Data and Computer Science, East Campus, SYSU<br/>
<br/>
Topic: Formalizing Winograd Schema Challenge problems in situation calculus and solving it using a theorem prover<br/>
Reporter: 董煜<br/>
Abstract: Winograd Schema Challenge (WSC) is a test of machine intelligence, as the substitution of Turing test. WSC contains a series of Winograd schema, a pronoun disambiguation problem. To correctly answer these problems, one requires commonsense knowledge of large-scale and reasoning. Since current method to acquire the commonsense knowledge for WSC and current natural language processing methods are not good enough，we choose to offer commonsense knowledge and translate WSC problems manually, and focus more on how to represent WSC problems and related knowledge in logical formulas, and reasoning the problems with theorem prover to solve them.<br/>
Reference:<br/>
<br/>
Topic: Verification-Based Generalized Planning Problem Solving<br/>
Reporter: 崔振河<br/>
Abstract: Generalized planning, where a single plan works for multiple instances, has recently been drawing increasing attention in the AI community. This research area mainly concerns about the following two issues: (1) How to solve a generalized planning problem? (2) How to guarantee the correctness of plans? The first is the most basic and important problem, and the second, is the most diffcult problem in the area of generalized planning. Theorem-proving techniques are often used to verify if a class of possibly infinite many dynamic systems with similar structure have certain properties, such as goal achiveability.<br/>
In this talk, I will discuss how to use theorem-proving techniques to ensure the correctness of solutions of generalized planning problems. Specifically, using the mathematical induction method to prove that a generalized planning problem is goal achievable; then, based on the inductive process, we can extract a sequence of actions as the solution of the generalized planning problem.  In addition, because existing theorem-proving techniques can only be used to prove the goal achievability of some simple generalized planning problems, I also show an extension of the existing theorem proving techniques.<br/>
Reference:<br/></div></li>

<li>March 18th, 2019 (Monday)<button class="button" id="show3182019" onclick="showOrHide(this)">...</button>
<div class=".elem" id="show3182019_info" style="height:0;overflow:hidden">
Time: 14:00 PM – 17:00 PM<br/>
Location: Room A318, School of Data and Computer Science, East Campus, SYSU<br/>
<br/>
Topic: Representation Learning for Classical Planning from Partially Observed Traces<br/>
Reporter: 林津霞<br/>
Abstract: Specifying the complete domain model by a human has a high cost, which impedes the planning techniques to be applied in many real-world scenarios. Most traditional domain-mode approaches output a domain model in form of the planning language STRIPS or PDDL and solve new planning instances by invoking an existing planner. However,  whether a plan can be found is sensitive to the accuracy of the learned domain model and it may fail if some critical effects are not learned correctly. In this paper, we propose a novel planning representation based on graph neural network (GNN) with propositions and states represented as vertexes and actions as vectors. The state progresses by performing an action when the proposition-state graph progresses with the edge being updated by the action vector. For such a planning representation, we propose a novel framework to learn domain models from partially observed traces, called LP-GNN. As the interpretation of propositions in a state is captured by edges, a new planning instance can be computed via the domain model learnt. Furthermore, thanks to vectorizing states, we propose an approach to learning the heuristic function based on the neural network to assist planning.<br/>
The results of the experiments on three well-known domains show that our approach outperforms the domain-model learner ARMS and the heuristic function learned is effective.<br/>
Reference:<br/>
<br/>
Topic: Efficient Sampling of SAT Solutions for Testing<br/>
Reporter: 钟洪桢<br/>
Abstract: In software and hardware testing, generating multiple inputs which satisfy a given set of constraints is an important problem with applications in fuzz testing and stimulus generation. However, it is a challenge to perform the sampling efciently, while generating a diverse set of inputs which satisfy the constraints. We developed a new algorithm QickSampler which requires a small number of solver calls to produce millions of samples which satisfy the constraints with high probability. We evaluate QickSampler on large real-world benchmarks and show that it can produce unique valid solutions orders of magnitude faster than other state-of-theart sampling tools, with a distribution which is reasonably close to uniform in practice.<br/>
Reference:<br/>
[1] Rafael Dutra, Kevin Laeufer, Jonathan Bachrach, Koushik Sen. Efficient sampling of SAT solutions for testing. ICSE 2018: 549-559<br/></div></li>

<li>March 11th, 2019 (Monday)<button class="button" id="show3112019" onclick="showOrHide(this)">...</button>
<div class=".elem" id="show3112019_info" style="height:0;overflow:hidden">
Time: 14:00 PM – 17:00 PM<br/>
Location: Room 607, School of Data and Computer Science, East Campus, SYSU<br/>
<br/>
Topic: How Agent Types Impact the Successfulness of Implicit Coordination<br/>
Reporter: 李晨阳<br/>
Abstract: How one agent’s planning will influence the others is an important problem in the multi-agents epistemic planning. Recent works show that policies with implicit coordination may be one way to solve a multi-agents planning from a single-agent perspective without communication. Thus, in this seminar, I will introduce how and under which circumstances the different types of decentralized agents with their policies will lead to the desired goals.<br/>
Reference:<br/>
[1] Bolander T, Engesser T, Mattmüller R, et al. Better eager than lazy? How agent types impact the successfulness of implicit coordination[C]. KR. 2018.<br/>
<br/>
Topic: Understanding with or without Models<br/>
Reporter: 何蔚楠<br/>
Abstract: As large-scale datasets pop up in the field of artificial intelligence, there are many neural approaches that benefit from the abundant training examples. The success of the model-free approach might eclipse the importance of world models, at least from a superficial perspective. In this talk, we will what might go wrong without understanding the world, and what merits could it be if one utilizes it.<br/>
Reference:<br/>
[1] Radford et al. Language Models are Unsupervised Multitask Learners. 2019.<br/>
[2] Yi et al. Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language Understanding. NeurIPS. 2018.<br/></div></li>

<li>March 4th, 2019 (Monday)<button class="button" id="show342019" onclick="showOrHide(this)">...</button>
<div class=".elem" id="show342019_info" style="height:0;overflow:hidden">
Time: 14:00 PM – 17:00 PM<br/>
Location: Room 607, School of Data and Computer Science, East Campus, SYSU<br/>
<br/>
Topic: An Incremental Evaluation Mechanism for the Critical Node Problem<br/>
Reporter: 方弼清<br/>
Abstract: The Critical Node Problem (CNP) is to identify a subset of nodes in a graph whose removal maxi- mally degrades pairwise connectivity. The CNP is an important variant of the Critical Node Detection Problem (CNDP) with wide applications. Due to its NP-hardness for general graphs, most works focus on local search algorithms that can return a good quality solution in a reasonable time. However, computing the objective function of CNP is a fre- quent procedure and is time-consuming (with com- plexity O(|V| + |E|)) during the search, which is a common problem that previous algorithms suffered from. In this paper, we propose a general incremen- tal evaluation mechanism (IEM) to compute the objective function with much lower complexity. In this work, we improved two important greedy oper- ations with IEM, along with experiments. Finally, we evaluate IEM by applying it into an evolutionary algorithm on two popular benchmarks, compared with the state-of-the-art approach. The experimen- tal results showed the significance of IEM.<br/>
Reference:<br/>
[1] "An Incremental Evaluation Mechanism for the Critical Node Problem".<br/>
<br/>
Topic: Combining Reinforcement Learning and Configuration Checking for Maximum k-plex Problem<br/>
Reporter: 陈沛林<br/>
Abstract: The Maximum k-plex Problem is an important combinatorial optimization problem with increasingly wide applications. Due to its exponential time complexity, many heuristic methods have been proposed which can return a good-quality solution in a reasonable time. However, most of the heuristic algorithms are memoryless and unable to utilize the experience during the search. Inspired by the multi-armed bandit (MAB) problem in reinforcement learning (RL), we propose a novel perturbation mechanism named BLP, which can learn online to select a good vertex for perturbation when getting stuck in local optima. To our best of knowledge, this is the first attempt to combine local search with RL for the maximum $ k $-plex problem. Besides, we also propose a novel strategy, named Dynamic-threshold Configuration Checking (DTCC), which extends the original Configuration Checking (CC) strategy from two aspects. Based on the BLP and DTCC, we develop a local search algorithm named BDCC and improve it by a hyperheuristic strategy. The experimental result shows that our algorithms dominate on the standard DIMACS and BHOSLIB benchmarks and achieve state-of-the-art performance on massive graphs.<br/>
Reference:<br/>
[1] "Combining Reinforcement Learning and Configuration Checking for Maximum k-plex Problem".<br/>
[2] Zhou Y, Hao J K. "Frequency-driven tabu search for the maximum s-plex problem"[J]. Computers & Operations Research, 2017, 86: 65-78.<br/></div></li>

                        <h3>2018 Fall</h3>
<li>题目：两个局部搜索技术<button class="button" id="show132019" onclick="showOrHide(this)">...</button>
<div class=".elem" id="show132019_info" style="height:0;overflow:hidden">
主讲人：蔡少伟 研究员 中科院软件所<br/>
日期：2019年1月3日（星期四）<br/>
时间：上午9:30am - 10:30am<br/>
地点：数据科学与计算机学院 A201<br/>
主持：万海 副教授 中山大学<br/>
摘要：<br/>
局部搜索是求解组合优化问题的一类主要方法，尤其被用于求解大规模组合优化问题。在局部搜索算法研究中，搜索策略和评分函数是两个主要的研究方向。本报告将介绍分别从这两个方面介绍两个局部搜索技术，这两个技术都已经成功运用于多个问题，取得很好的效果。第一个技术是格局检测策略，该技术通过避免局部循环，有效减少局部搜索的循环现象，从而显著提高局部搜索算法的性能。第二个技术是子分函数，该函数是首个考虑约束满足度的评分函数，能广泛用于约束问题的局部搜索算法。<br/>
个人介绍：<br/>
蔡少伟，中科院软件所 计算机科学国家重点实验室 研究员，中国科学院大学岗位教授。于2012年和2014年分别获北京大学计算机博士学位和 Griffith大学应用数学博士学位，获得中科院软件所杰出青年荣誉称号。主要研究方向为组合优化，自动推理，以及自动算法工程。发表论文50余篇，以一作/通讯作者发表CCF A类论文，ACM Trans., IEEE Trans. 30多篇，在命题逻辑可满足性问题(SAT)和最大可满足性问题(MaxSAT)国际比赛中多次获得冠军。多年担任人工智能顶级会议IJCAI和AAAI的PC member，任SCI期刊Frontiers of Computer Science的Young Associate Editor。<br/></div></li>

<li>December 26th, 2018 (Wednesday)<button class="button" id="show12262019" onclick="showOrHide(this)">...</button>
<div class=".elem" id="show12262019_info" style="height:0;overflow:hidden">
Time: 09:00 AM – 11:30 AM<br/>
Location: Room 607, School of Data and Computer Science, East Campus, SYSU<br/>
<br/>
Topic: Generalized Planning: Synthesizing Plans that Work for Multiple Environments<br/>
Reporter: 崔振河<br/>
Abstract: Generalized planning has the advantage that if a generalized solution is found for a problem class, then solving any other instances in the class only require the execution of the generalized plan. In this work, authors proposed a formal definition of generalized planning that is independent of any representation formalism. They assume that generalized plans must work on a set of unrelated deterministic environments. For a finite set of environments, they prove that generalized planning is always decidable and EXPSPACE-complete. For the infinite case, they show that the “one-dimensional problems” with the restriction of finite-state plans is EXPSPACE-decidable.<br/>
Reference:<br/>
[1] Hu Y, De Giacomo G. "Generalized Planning: Synthesizing Plans that Work for Multiple Environments". IJCAI 2011.<br/>
<br/>
Topic: Abstraction and Forgetting in the Situation Calculus<br/>
Reporter: 罗凯伦<br/>
Abstract: The thought of abstraction is widely used in Artificial Intelligence. Roughly speaking, abstraction involves the process of concentrating on important contents while ignoring their unimportant details, or generalizing concrete ideas to abstract ones. Recently, a theoretical agent abstraction framework was proposed in the situation calculus, where abstraction is viewed as a mapping from a high-level action theory to a low-level action theory, and so-called sound or/and complete abstraction can be defined respectively. In this paper, we continue to study abstraction in the situation calculus via a well-studied concept called forgetting. First, we show how the abstraction semantic and the forgetting semantic can be correlated. Second, we give a general computation method for computing high-level action theories of abstraction through forgetting given low-level action theories and mappings. Last, under propositional cases, we implement our method and apply abstraction to the planning area for improving planners' efficiency.<br/>
Reference:<br/></div></li>

<li>December 19th, 2018 (Wednesday)<button class="button" id="show12192019" onclick="showOrHide(this)">...</button>
<div class=".elem" id="show12192019_info" style="height:0;overflow:hidden">
Time: 09:00 AM – 11:30 AM<br/>
Location: Room 607, School of Data and Computer Science, East Campus, SYSU<br/>
<br/>
Topic: Neural Motifs: Scene Graph Parsing with Global Context<br/>
Reporter: 王宝亿<br/>
Abstract: We investigate the problem of producing structured graph representations of visual scenes. Our work analyzes the role of motifs: regularly appearing substructures in scene graphs. We present new quantitative insights on such repeated structures in the Visual Genome dataset. Our analysis shows that object labels are highly predictive of relation labels but not vice-versa. We also find that there are recurring patterns even in larger subgraphs: more than 50% of graphs contain motifs involving at least two relations. Our analysis motivates a new baseline: given object detections, predict the most frequent relation between object pairs with the given labels, as seen in the training set. This baseline improves on the previous state-of-the-art by an average of 3.6% relative improvement across evaluation settings. We then introduce Stacked Motif Networks, a new architecture designed to capture higher order motifs in scene graphs that further improves over our strong baseline by an average 7.1% relative gain.<br/>
Reference:<br/>
[1] Rowan Zellers, Mark Yatskar, Sam Thomson, Yejin Choi. "Neural Motifs: Scene Graph Parsing with Global Context". CVPR18.<br/>
<br/>
Topic: A Survey on Combinatorial Interaction Testing and Software Product Lines<br/>
Reporter: 陈沛林<br/>
Abstract: Combinatorial Interaction Testing (CIT) is a testing method that models a System Under Test (SUT) as a set of factors (choice points or parameters) each taking its values from a particular domain. Software Product Lines (SPLs) are families of related systems whose members are distinguished by the set of features they provide. Two domaining algorithms for CIT are greedy algorithm and meta-heuristic algorithm. The former tend to run faster while the latter usually discover better solutions. We are planning to apply meta-heuristic framework to the CIT for SPL, which is a well-known NP-hard problem.<br/>
Reference:<br/>
[1] Lin J, Luo C, Cai S, et al. "Tca: An efficient two-mode meta-heuristic algorithm for combinatorial test generation" ASE15.<br/>
[2] Lopez-Herrejon R E, Fischer S, Ramler R, et al. "A first systematic mapping study on combinatorial interaction testing for software product lines". ICSTW15.<br/></div></li>

<li>December 12th, 2018 (Wednesday)<button class="button" id="show12122019" onclick="showOrHide(this)">...</button>
<div class=".elem" id="show12122019_info" style="height:0;overflow:hidden">
Time: 09:00 AM – 11:30 AM<br/>
Location: Room 607, School of Data and Computer Science, East Campus, SYSU<br/>
<br/>
Topic: Learning Features and Abstract Actions for Computing Generalized Plans<br/>
Reporter: 李嘉乐<br/>
Abstract: Generalized planning is concerned with the computation of plans that solve not one but multiple instances of a planning domain. In the authors' previous work, they show that generalized plans can be expressed as mappings of feature values into actions, and that they can often be computed with fully observable non-deterministic (FOND) planners. However, the formulation assumes that a set of common features and a set of abstract actions are given. In this work, they propose a way to learn them automatically. Based on a Max SAT formulation, it yields the features and abstract actions from sampled state transitions. Then a FOND planner uses this information to produce the general plans. In this talk, I will introduce this method and the correctness guarantees, and show the experimental results.<br/>
Reference:<br/>
[1] Blai Bonet, Guillem Frances, Hector Geffner. "Learning Features and Abstract Actions for Computing Generalized Plans". AAAI19<br/>
<br/>
Topic: Automatic verification of liveness properties in the situation calculus<br/>
Reporter: 李健<br/>
Abstract: Liveness(reachability) and safety are equally important in the program verification. In our research, we propose a sound but incomplete method to verify the reachability of the goal. Given a basic action theory and a goal, first we use SMT to automatically generate an initial state, next construct a planning problem according to the state and the goal. Then we obtain a query of which the decreasing times is the largest in the planning path. Finally, we use inductive method to verify that the number of the query is reduced after a corresponding action is performed, which shows that the goal is reachable.<br/>
Reference:</div></li>

<li>December 5th, 2018 (Wednesday)<button class="button" id="show1252018" onclick="showOrHide(this)">...</button>
<div class=".elem" id="show1252018_info" style="height:0;overflow:hidden">
Time: 09:00 AM – 11:30 AM<br/>
Location: Room 607, School of Data and Computer Science, East Campus, SYSU<br/>
<br/>
Topic: Link Prediction for Scene Graphs based on Metric Learning<br/>
Reporter: 梁锦瑞<br/>
Abstract: Metric learning has been well applied in the field of face recognition. For example, in the practical application of face recognition, the best model will force each person's training faces to be as close as possible to the person’s template face, while stay away from the template face which does not belong to the person. We will introduce a novel idea to apply metric learning to link prediction for scene graphs. In the scene graph, we will first use the deep CNN to jointly encode the head and tail entities in the visual triplet to obtain the feature vector of the entity pair (head, tail). Using metric learning, the model will force the entity pair feature to be as close as possible to its relation template, while stay away from relation templates that do not belong to the entity pair. After the model has been completely trained, we can use the distance between the entity pair and relation templates to determine which relation the entity belongs to and complete link prediction task in scene graphs.<br/>
Reference:<br/>
[1] Hao Wang, Yitong Wang, Zheng Zhou, Xing Ji, Dihong Gong, Jingchao Zhou, Zhifeng Li and Wei Liu. "CosFace: Large Margin Cosine Loss for Deep Face Recognition." In CVPR, pp. 5265-5274. 2018.<br/>
<br/>
Topic: Visual Relationship Detection with Deep Structural Ranking<br/>
reporter: 陈海城<br/>
Abstract: Visual Relationship Detection aims to localize a pair of objects and determine the predicate between them. With the incomplete annotations for visuala relationships, it is usually difficult to model training and evalution. In this paper, it proposes a new structural ranking loss-based framework integrating multiple cues to detect visual relation.<br/>
Reference:<br/>
[1] Kongming Liang, Yuhong Guo, Hong Chang, Xilin Chen. "Visual Relationship Detection with Deep Structural Ranking." AAAI. 2018.</div></li>

<li>November 28th, 2018 (Wednesday)<button class="button" id="show11282018" onclick="showOrHide(this)">...</button>
<div class=".elem" id="show11282018_info" style="height:0;overflow:hidden">
Time: 09:00 AM – 11:30 AM<br/>
Location: Room 607, School of Data and Computer Science, East Campus, SYSU<br/>
<br/>
Topic: Situation Calculus Semantics for Actual Causality<br/>
Reporter: 董昱<br/>
Abstract: Actual causality is concerned with finding in a given scenario a singualr event that caused another event. In Winograd Schema Challenge, all problems are in one scenario and many of them fits the definition of actual causality. In this paper, they build their definition of actual cause in the context of situation calculus action theories with sequential actions. They provide a formal translation from causal models to situation calculus.<br/>
Reference:<br/>
[1] Batusov, Vitaliy, and Mikhail Soutchanski. "Situation Calculus Semantics for Actual Causality." AAAI. 2018.<br/>
<br/>
Topic: Crowdsourcing Knowledge about Daily Events<br/>
reporter: 何蔚楠<br/>
Abstract: Commonsense knowledge has attracted much attention lately in the field of artificial intelligence. Even though little effort surfaces concerning the mechanism behind commonsense, there are many attempts to automate the acquisition of commonsense knowledge. Yet, the reporting bias of our daily-used natural language text hinders a comprehensive extraction. In this talk, we will see how researchers from the Allen Institute and the University of Washington acquire certain inferential knowledge about daily events using crowdsourcing.<br/>
Reference:<br/>
[1] Maarten Sap, Ronan LeBras, Emily Allaway, Chandra Bhagavatula, Nicholas Lourie, Hannah Rashkin, Brendan Roof, Noah A Smith & Yejin Choi (2019). ATOMIC: An Atlas of Machine Commonsense for If-Then Reasoning. AAAI (https://homes.cs.washington.edu/~msap/pdfs/sap2019atomic.pdf)</div></li>

<li>题目：自动驾驶技术及安全模型<button class="button" id="show11232018" onclick="showOrHide(this)">...</button>
<div class=".elem" id="show11232018_info" style="height:0;overflow:hidden">
<br/>
主讲人：吉建民 副教授 中国科学技术大学<br/>
<br/>
日期：2018年11月23日（星期五）<br/>
<br/>
时间：上午9:30am - 10:30am<br/>
<br/>
地点：数据科学与计算机学院 A201<br/>
<br/>
主持：万海 副教授<br/>
<br/>
摘要：<br/>
<br/>
        自动驾驶汽车从根本上改变了传统的“人—车—路”闭环控制方式，是通过车载传感系统感知道路环境、自动规划行车路线并控制车辆到达预定目标的智能汽车。为了适应我国相对复杂的道路交通运行环境，消除自动驾驶汽车上公共道路行驶存在的交通安全隐患，自动驾驶汽车应进行严格的环境适应性和技术安全性测试。然而采用路测和仿真的安全测试方法，无法使自动驾驶系统达到期望的安全程度。安全规则可以看成是自动驾驶的交通规则，可以保证车辆行为决策的安全性。目前采用形式化方法，通过模型抽象、安全规则定义和安全规则性质证明，可以从根本上证明一组安全规则的可行性。<br/>
<br/>
个人介绍：<br/>
<br/>
吉建民，男，1984年出生，博士，中国科学技术大学副教授。2005年毕业于中国科学技术大学计算机系，2010年于中国科学技术大学获计算机应用博士学位，后赴香港科技大学计算机科学与工程系任博士后，现任职于中国科学技术大学计算机科学与技术学院多智能体系统实验室。主要研究方向：知识表示与推理，智能机器人控制。作为骨干成员参与智能服务机器人项目——科大“可佳”工程。多次担任IJCAI, KR, AAAI, ICLP, AAMAS等国际人工智能会议的审稿人，并任AAAI-2011,IJCAI-2011的程序委员会委员。近三年在国际会议和期刊上发表论文多篇，合作翻译著作1本。<br/>
<br/>
<br/>
题目：知识图谱前沿研究及应用：语义集成<br/>
<br/>
主讲人：胡伟 副教授 南京大学<br/>
<br/>
日期：2018年11月22日（星期四）<br/>
<br/>
时间：上午9:30am - 10:30am<br/>
<br/>
地点：数据科学与计算机学院 A201<br/>
<br/>
主持：万海 副教授 中山大学<br/>
<br/>
摘要：<br/>
<br/>
知识图谱以结构化的方式描述客观世界中概念、实体及其间的关系，将互联网的信息表达成更接近人类认知世界的形式，提供了一种更好地组织、管理和理解互联网海量信息的能力。知识图谱可以由任何机构和个人自由构建，其背后的数据来源广泛、质量参差不齐，导致它们之间存在多样性和异构性。例如，对于相交领域，通常会存在多个不同的实体指称真实世界中的相同事物。语义集成的目标就是将不同知识图谱融合为一个统一、一致、简洁的形式，为使用不同知识图谱的应用程序间的交互建立互操作性。常用技术方法包括本体匹配、实例匹配以及知识融合等。本次讲座内容包括语义集成的技术方法和研究现状，并简要介绍我们的工作进展，最后对表示学习、人机协作等语义集成的未来研究方向进行展望。<br/>
<br/>
个人介绍：<br/>
<br/>
胡伟，博士，南京大学计算机科学与技术系副教授。主要研究方向为数据集成、知识挖掘、Web应用。2005年、2009年分别于东南大学计算机科学与工程学院获学士、博士学位。2009年底加入南京大学工作。2007年11月至2008年5月赴荷兰阿姆斯特丹自由大学联合培养，2008年9月至2008年12月赴IBM中国研究院（北京）实习，2014年9月至2015年9月赴美国斯坦福大学访学，2016年11月至2017年5月赴美国德州大学阿灵顿分校访学，2017年6月至2017年11月赴加拿大多伦多大学访学。主持国家自然科学基金面上/青年项目、教育部博士点基金、江苏省自然科学基金等项目。在WWW、AAAI、ISWC、Journal of Web Semantics等领域顶级国际会议和期刊上发表多篇论文，他引超千次，还获得过JIST最佳论文奖、ISWC最佳论文提名。担任中文信息学会语言与知识计算专业委员会委员、江苏省大数据专家委员会副秘书长，并多年担任WWW、AAAI、ISWC、中国数据库学术会议等国内外会议的程序委员。获得南京大学“大学生创新性实验计划项目”优秀指导教师称号，入选南京大学优秀中青年教师境外研修计划。</div></li>

<li>November 7th, 2018 (Wednesday)<button class="button" id="show1172018" onclick="showOrHide(this)">...</button>
<div class=".elem" id="show1172018_info" style="height:0;overflow:hidden">
Time: 09:00 AM – 11:30 AM<br/>
Location: Room 607, School of Data and Computer Science, East Campus, SYSU<br/>
<br/>
Topic: Commonsense Knowledge Aware Conversation Generation with Graph Attention<br/>
reporter: 林子莨<br/>
Abstract: In this paper, we present a novel open-domain conversation generation model to demonstrate how large-scale commonsense knowledge can facilitate language understanding and generation. Given a user post, the model retrieves relevant knowledge graphs from a knowledge base and then encodes the graphs with a static graph attention mechanism, which augments the semantic information of the post and thus supports better understanding of the post. Then, during word generation, the model attentively reads the retrieved knowledge graphs and the knowledge triples within each graph to facilitate better generation through a dynamic graph attention mechanism.<br/>
Reference:<br/>
[1] Zhou, Hao, Tom Young, Minlie Huang, Haizhou Zhao, Jingfang Xu, and Xiaoyan Zhu. "Commonsense Knowledge Aware Conversation Generation with Graph Attention." In IJCAI, pp. 4623-4629. 2018.<br/>
<br/>
Topic: SDRL: Interpretable and Data-efficient Deep Reinforcement Learning Leveraging Symbolic Planning<br/>
reporter: 刘昭帅<br/>
Abstract: In order to improve the data-efficientcy and interpretability of Deep Reinforcement Learning (DRL), this paper proposes a framework of Symbolic Deep Reinforcement Learning (SDRL) featuring a planner-controller-meta-controller architecture. The three key components of the architecture take charge of subtask scheduling, data-driven subtask learning, and subtask evaluation, respectively. They can cross-fertilize each other and eventually converge to an optimal symbolic plan along with the learned subtasks. What's more, experimental results validate the interpretability of subtasks, along with improved data efficiency compared with state-of-the-art approaches. It is likely that this paper's work is the first work that integrates symbolic planning with DRL that gains interpretability and data-efficiency.<br/>
Reference:<br/>
[1] Daoming Lyu, Fangkai Yang, Bo Liu, Steven Gustafson. "SDRL: Interpretable and Data-efficient Deep Reinforcement Learning Leveraging Symbolic Planning." In AAAI'19.</div></li>

<li>October 31st, 2018 (Wednesday)<button class="button" id="show10312018" onclick="showOrHide(this)">...</button>
<div class=".elem" id="show10312018_info" style="height:0;overflow:hidden">
Time: 09:00 AM – 11:30 AM<br/>
Location: Room 607, School of Data and Computer Science, East Campus, SYSU<br/>
<br/>
Topic: PEORL: Integrating Symbolic Planning and Hierarchical Reinforcement Learning for Robust Decision-Making<br/>
reporter: 刘亚男<br/>
Abstract: Reinforcement learning and symbolic planning have both been used to build intelligent autonomous agents. Reinforcement learning relies on learning from interactions with real world, which often requires an unfeasibly large amount of experience. Symbolic planning relies on manually crafted symbolic knowledge, which may not be robust to domain uncertainties and changes. In this paper we present a unified framework PEORL that integrates symbolic planning with hierarchical reinforcement learning (HRL) to cope with decision-making in a dynamic environment with uncertainties. Symbolic plans are used to guide the agent’s task execution and learning, and the learned experience is fed back to symbolic knowledge to improve planning. This method leads to rapid policy search and robust symbolic plans in complex domains. The framework is tested on benchmark domains of HRL.<br/>
Reference:<br/>
[1] Yang F, Lyu D, Liu B, et al. PEORL: Integrating Symbolic Planning and Hierarchical Reinforcement Learning for Robust Decision-Making[J]. arXiv preprint arXiv:1804.07779, 2018.<br/>
<br/>
Ongoing work report: Transfer learning HTN domain from different HTN domains<br/>
reporter: 林津霞<br/>
<br/>
Topic: Modeling Rational Agents with a BDI-Architecture<br/>
Speaker: 李晨阳<br/>
Abstract: In this paper, the authors regard the intention as an integral part of the mental state of an agent, this shows that intention has equal status with notions of belief and desire, thus, they presented a formalization of intentions which realize many of the important elements of Bratman’s theory based on a branching-time possible-worlds model. Moreover, they present 3 types of rational agents, and show their commitment strategies. Finally, they compared their formalization of intentions with Bratmans’s theory and Cohen&Levesque’s formalization of intentions.<br/>
Reference:<br/>
[1] A. Rao and M. Georgeff. Modeling Rational Agents with a BDI-Architecture. In R. Fikes and E. Sandewall,Proc.of the 2nd International Conference on Principles of KR, pages 473-484, 1991.</div></li>

<li>October 24th, 2018 (Wednesday)<button class="button" id="show10242018" onclick="showOrHide(this)">...</button>
<div class=".elem" id="show10242018_info" style="height:0;overflow:hidden">
Time: 09:00 AM – 11:30 AM<br/>
Location: Room 607, School of Data and Computer Science, East Campus, SYSU<br/>
<br/>
Topic: Improve plan quality with HTN Learning and Reinforcement Learning<br/>
reporter: 林津霞<br/>
Abstract: We consider how to learn Hierarchical Task Networks(HTNs) for planning problems in which both the quality of solution plans generated by the HTNs and the speed at which those plans are found is important. We describe an integration of HTN Learning with Reinforcement Learning to both learn methods by analyzing semantic annotations on tasks and to produce estimates of the expected values of the learned methods by performing Monte Carlo updates. We performed an experiment in which plan quality was inversely related to plan length. In two planning domains, we evaluated the planning performance of the learned methods in comparison to two state-of-the-art satisficing classical planners, FASTFORWARD and SGPLAN6, and one optimal planner, HSP*F . The results demonstrate that a greedy HTN planner using the learned methods was able to generate higher quality solutions than SGPLAN6 in both domains and FASTFORWARD in one. Our planner, FASTFORWARD, and SGPLAN6 ran in similar time, while HSP*F was exponentially slower.<br/>
Reference:<br/>
[1] Hogg, C.; Kuter, U.; and Munoz-Avila, H. 2010. Learning Methods to Generate Good Plans: Integrating HTN Learning and Reinforcement Learning. In Proceedings of AAAI-10.<br/>
<br/>
Topic: Epistemic Partition Diagrams A Partition-Based Representation for the Modal Logic S5<br/>
Speaker: 温达城、吕方<br/>
Abstract: In this paper, we propose a new representation for subjective S5, called Epistemic Partition Diagrams (EPD), and its fragment EPD b , both of which are based on the notion of partition-based decomposition. The motivation of our study is to introduce a novel language to deal with the intractability of modal logic S5 and improving the efficiency in solving epistemic planning problems. Besides the compilation converting epistemic literal into EPD, we also introduce the properties of EPD, including with EPD b , in terms of succinctness and their support for queries and transformations by comparing them with those in ESD and several normal form of s-S5-DNF_{L, L_0}. Our result shows that EPD is more succinct than ESD and EPD_b is equally succinct with ESD, while all of them share the same properties in supporting queries and transformations except that EPD does not support polytime test for model checking.<br/>
Reference:<br/>
[1] Epistemic Partition Diagrams A Partition-Based Representation for the Modal Logic S5</div></li>

<li>October 17th, 2018 (Wednesday)<button class="button" id="show10172018" onclick="showOrHide(this)">...</button>
<div class=".elem" id="show10172018_info" style="height:0;overflow:hidden">
Time: 09:00 AM – 11:30 AM<br/>
Location: Room 607, School of Data and Computer Science, East Campus, SYSU<br/>
<br/>
Topic: Improve plan quality with HTN Learning and Reinforcement Learning<br/>
reporter: 林津霞<br/>
Abstract: We consider how to learn Hierarchical Task Networks(HTNs) for planning problems in which both the quality of solution plans generated by the HTNs and the speed at which those plans are found is important. We describe an integration of HTN Learning with Reinforcement Learning to both learn methods by analyzing semantic annotations on tasks and to produce estimates of the expected values of the learned methods by performing Monte Carlo updates. We performed an experiment in which plan quality was inversely related to plan length. In two planning domains, we evaluated the planning performance of the learned methods in comparison to two state-of-the-art satisficing classical planners, FASTFORWARD and SGPLAN6, and one optimal planner, HSP*F . The results demonstrate that a greedy HTN planner using the learned methods was able to generate higher quality solutions than SGPLAN6 in both domains and FASTFORWARD in one. Our planner, FASTFORWARD, and SGPLAN6 ran in similar time, while HSP*F was exponentially slower.<br/>
Reference:<br/>
[1] Hogg, C.; Kuter, U.; and Munoz-Avila, H. 2010. Learning Methods to Generate Good Plans: Integrating HTN Learning and Reinforcement Learning. In Proceedings of AAAI-10.<br/>
<br/>
Topic: Research on the abstraction and solution method of generalized planning<br/>
Speaker: 崔振河<br/>
Abstract: Generalized planning, where a single plan works for multiple instances, has recently been drawing increasing attention in the AI community. This form of planning has the advantage that if a generalized solution is found for a problem class, then solving any instance in the class only requires the execution of the generalized plan. In this report, I will introduce the background of generalized planning and some related research results. This is followed by a summary of some existing problems in the field of generalized planning. Finally, I would like to introduce my future work on generalized planning and the relevant research plans to be adopted.</div></li>

<li>October 10th, 2018 (Wednesday)<button class="button" id="show10102018" onclick="showOrHide(this)">...</button>
<div class=".elem" id="show10102018_info" style="height:0;overflow:hidden">
Time: 09:00 AM – 11:30 AM<br/>
Location: Room 607, School of Data and Computer Science, East Campus, SYSU<br/>
<br/>
Topic: Representation Learning for Scene Graph Completion via Neural Network<br/>
Speaker: 王宝亿<br/>
Abstract: Inspired by the paper “Convolutional 2D Knowledge Graph Embeddings”[1], I thought that some methods used for knowledge graph completion might be migrated to scene graph. Therefore, I propose a new idea to integrate the structural information and visual information of scene graph using neural network. The advantage of neural network is that it can be seen as a black box to describe the relationship between inputs and outputs. First, I will give the motivation for this work. Then, I will describe the challenge. Finally, I will introduce the latest results in knowledge graph.<br/>
Reference:<br/>
[1] Convolutional 2D Knowledge Graph Embeddings<br/>
[2] Representation Learning for Scene Graph Completion via Jointly Structural and Visual Embedding<br/>
<br/>
Topic: Iterative Visual Relationship Detection via Commonsense Knowledge Graph<br/>
Speaker: 欧佳玲<br/>
Abstract: Inspired by iterative visual reasoning in image recognition, we propose a novel model to take the advantage of common sense in the form of the knowledge graph in visual relationship detection, named Iterative Visual Relationship Detection with Commonsense Knowledge Graph (IVRDC). Our model consists of two modules: a feature module that predicts predicates by visual features and semantic features with a bi-directional RNN; and a commonsense knowledge module that constructs a specific commonsense knowledge graph for predicate prediction. After iteratively combining prediction from both modules, IVRDC updates the memory and commonsense knowledge graph. The final predictions are made by taking the result of each iteration into account with an attention mechanism. Our experiments on the Visual Relationship Detection(VRD) dataset and the Visual Genome(VG) dataset demonstrate that our proposed model surpasses prior start-of-the-art results.<br/>
Reference:<br/>
[1] AAAI2019@ivrdc</div></li>

<li>September 26th, 2018 (Wednesday)<button class="button" id="show9262018" onclick="showOrHide(this)">...</button>
<div class=".elem" id="show9262018_info" style="height:0;overflow:hidden">
Time: 09:00 AM – 11:30 AM<br/>
Location: Room 607, School of Data and Computer Science, East Campus, SYSU<br/>
<br/>
Topic: Generalized Planning via CDNF Learning<br/>
Speaker: 李嘉乐<br/>
Abstract: Generalized planning problems aim at finding a general solution for a set of classical planning problems with the same domain. In this paper, we focus on generalized policies that can be represented as a condition for each operator. We propose a method to automatically generate such policies from problem specifications. In our method, we first generate all the problem instances with number of objects no more than a given bound. Then we generate the transition graph for each instance. We propose a heuristic method to derive a set of first-order formulas as the feature set, and use it to do state abstraction. Then we use a partial MaxSAT solver to choose one solution for each instance so that for each operator, we can use the least number of features to describe its condition. Finally, from the chosen solutions, we apply the CNDF algorithm from the literature to learn a conjunction of DNF formulas as the condition for each operator. Experiments show that our methods can effectively solve many challenging generalized problems, and the learnt policies have succinct conditions.<br/>
Reference:<br/>
[1] aaai19<br/>
<br/>
Topic: Automatic Verification of FSA Strategies via Counterexample-Guided Local Search for Invariants<br/>
Speaker: 罗凯伦<br/>
Abstract: Strategy representation and reasoning has received much attention over the past years. In this paper, we consider the representation of structured strategies and their automatic verification. We propose a graphic representation of strategies where a strategy is represented by an FSA (Finite State Automaton) with edges labelled by restricted Golog programs. FSA representation of strategies has the advantages of ease to represent nested loop structures and amenability to algorithmic operations. We formalize the semantics of FSA strategies in the situation calculus. When it comes to formal verification, the methods of predicate abstraction and counterexample-guided refinement are widely used. The concept of invariants can be naturally extended to FSA strategies. In this paper, we propose a method for verifying whether an FSA strategy is a winning strategy by counterexample-guided local search for appropriate invariants. We implemented our method and did experiments on two-player domains from the combinatorial game literature. We also tested our method with single-agent domains from the planning literature by adapting them into our framework. Experimental results showed that our system can successfully verify most of them within a reasonable amount of time.<br/>
Reference:<br/>
[1] paper4244</div></li>

<li>September 19th, 2018 (Wednesday)<button class="button" id="show9192018" onclick="showOrHide(this)">...</button>
<div class=".elem" id="show9192018_info" style="height:0;overflow:hidden">
Time: 09:00 AM – 11:30 AM<br/>
Location: Room 607, School of Data and Computer Science, East Campus, SYSU<br/>
<br/>
Topic: Bi-Kronecker Functional Diagrams: A Novel Canonical Representation of Boolean Functions<br/>
Speaker: 黄炫翔<br/>
Abstract: In this paper, we present a novel data structure for compact representation and effective manipulation of Boolean functions, called Bi-Kronecker Functional Diagrams (BKFDDs). BKFDDs integrates the classical expansions (the Shannon and Davio expansions) and their bi-version. Thus, BKFDDs are generalizations of existing decision diagrams: BDDs, FDDs, KFDDs and BBDDs. Interestingly, under certain conditions, it is sufficient to consider the above expansions (the classical expansions and their bi-versions). By imposing reduction and ordering rules, BKFDDs are compact and canonical forms of Boolean functions. The experimental results demonstrate that BKFDDs outperform other existing decision diagrams in terms of size.<br/>
Reference:<br/>
[1] Bi-Kronecker Functional Diagrams: A Novel Canonical Representation of Boolean Functions<br/>
<br/>
Topic: Interpolation for Prime Compilation of Non-Clausal Formulae<br/>
Speaker: 罗炜麟<br/>
Abstract: Prime compilation, i.e., the generation of all prime implicates or implicants, is a prominent fundamental issue for Artificial Intelligence. Recently, the prime compilation for non-clausal formulae has received more attention. The state-of-the-art approach for non-clausal formulae is to construct a prime cover of the formula, with its all prime implicates or implicants found at the same time. However, constructing a prime cover takes much time. To tackle this challenge, this paper focuses on an over-approximate method to construct a cover. Motivated by the applications of Graig interpolant in optimizing large-scale search problems, we propose an interpolation-based approach for non-clausal formulae. Our approach consists of two stages. First, we rewrite the non-clausal formula into a cover by using a set of over-approximate prime implicates. Second, based on this cover, we generate all the prime implicates or implicants. Moreover, we propose the bisecting and the jumping backtracking to improve efficiency. The experimental results show that our approach outperforms the state-of-the-art approaches.<br/>
Reference:<br/>
[1] Interpolation for Prime Compilation of Non-Clausal Formulae</div></li>

<li>September 12th, 2018 (Wednesday)<button class="button" id="show9122018" onclick="showOrHide(this)">...</button>
<div class=".elem" id="show9122018_info" style="height:0;overflow:hidden">
Time: 09:00 AM – 11:30 AM<br/>
Location: Room 607, School of Data and Computer Science, East Campus, SYSU<br/>
<br/>
Topic: Bi-Kronecker Functional Diagrams: A Novel Canonical Representation of Boolean Functions<br/>
Speaker: 黄炫翔<br/>
Abstract: In this paper, we present a novel data structure for compact representation and effective manipulation of Boolean functions, called Bi-Kronecker Functional Diagrams (BKFDDs). BKFDDs integrates the classical expansions (the Shannon and Davio expansions) and their bi-version. Thus, BKFDDs are generalizations of existing decision diagrams: BDDs, FDDs, KFDDs and BBDDs. Interestingly, under certain conditions, it is sufficient to consider the above expansions (the classical expansions and their bi-versions). By imposing reduction and ordering rules, BKFDDs are compact and canonical forms of Boolean functions. The experimental results demonstrate that BKFDDs outperform other existing decision diagrams in terms of size.<br/>
Reference:<br/>
[1] Bi-Kronecker Functional Diagrams: A Novel Canonical Representation of Boolean Functions<br/>
<br/>
Topic: ECASL: A Model of Rational Agency for Communicating Agents<br/>
Speaker: 李晨阳<br/>
Abstract: Most agent theories pay a little attention on the intention expression which concluded in two problem: how the agents will achieve goals and how they plan or commit the plan. One thread to avoid the first problem is Cognitive Agent Specification Language (CASL), it aims to close the gap between agents’ intentions to achieve a state and their intentional actions.<br/>
In this paper, the authors extend the version of CASL to ECASL (Extended CASL), they develop a simple formalization of cooperative ability for agents working in a multi-agent setting. Also, they relate future and present directed intentions with definition of rational plan.<br/>
Reference:<br/>
[1] Shakil M.Khan, Yves. Lespérance ECASL: a model of rational agency for communicating agents. AAMAS 2005: 762-769</div></li>

<li>September 5th, 2018 (Wednesday)<button class="button" id="show952018" onclick="showOrHide(this)">...</button>
<div class=".elem" id="show9520189_info" style="height:0;overflow:hidden">
Time: 09:00 AM – 11:30 AM<br/>
Location: Room 607, School of Data and Computer Science, East Campus, SYSU<br/>
<br/>
Topic: Using SAT-based Techniques in Power Estimation<br/>
Speaker: 钟洪桢<br/>
Abstract: The estimation of maximum possible power in VLSI circuits is essential for determining the appropriate packaging and cooling techniques and for optimizing the power and ground routing networks. In VLSI, it was proven that maximizing dissipation is equivalent to maximizing gate output activity, appropriately weighted to account for differing load capacitances. The problem of estimation of maximum possible power is converted to identifying an input vector pair that maximizes the weighted circuit activity. We introduce using SAT-Based and generic Integer Linear Programming(ILP) solvers to find a solution. The experimental resultsobtained on a large number of benchmark circuits provide promising evidence that the proposed complete approach is both viable and useful and outperforms the random approach.<br/>
Reference:<br/>
[1] Roy S, Chakrabarti P P, Dasgupta P. Bounded delay timing analysis and power estimation using SAT[J]. Microelectronics Journal, 2010, 41(5): 317-324.<br/>
[2] Sagahyroon A, Aloul F A. Using SAT-based techniques in power estimation[J]. Microelectronics Journal, 2007, 38(6-7): 706-715.<br/>
<br/>
Topic: Local Search Algorithm for Maximum k-Plexes<br/>
Speaker: 陈沛林<br/>
Abstract: A clique model is one of the most important techniques on the cohesive subgraph detection; however, its applications are rather limited due to restrictive conditions of the model. The maximum k-plex, as a generalization of maximun clique, is an important model for social network analysis. For a given integer k > 0, a k-plex in G = (V, E) is a subset of V, denoted as S,  where the degree of every node in the associated induced subgraph is at least |S| - k. When k = 1 a k-plex represents a clique. Several algorithms were developed to solve the maximum k-plex, including exact algorithms as well as heuristic methods.<br/>
A frequency-driven tabu search algorithm was proposed by Yi Zhou and Jin-Kao Hao in 2017 to solve the maximum k-plex problem. In this paper, the auther defines two operator, ADD and SWAP, to locate high-quality solutions, and a operator, Press, to escape the local optimum traps. To avoid revisiting recently examined solutions, the author use a tabu list to record the vertices that are just dropped from the current solution.<br/>
An exact algorithm for maximum k-plex in massive graphs is proposed by Jian Gao et al. in 2018. In this paper, the author presents some properies, which can be used to estimate the upper bound and lower bound of the number of the maximum k-plex for a given graph, to help reducing the graph during the search for maximum k-plex. The experiments shows that the reduction strategies works very well and the proposed algorithm outperforms the state-of-the-art ones, especially for the massive graphs. However, when solving the dense graphs, the performance of the proposed algorithm is not so good.<br/>
Reference:<br/>
[1] Gao J, Chen J, Yin M, et al. An Exact Algorithm for Maximum k-Plexes in Massive Graphs[C]//IJCAI. 2018: 1449-1455.<br/>
[2] Zhou Y, Hao J K. Frequency-driven tabu search for the maximum s-plex problem[J]. Computers & Operations Research, 2017, 86: 65-78.</div></li>

                        <h3>2017 Spring</h3>
...
                    </ul>
            </div>
        </div>
                <hr>
    <div class="sysubot">
                <p>
                    <font color="white">Last Updated: Apr 2019</font>
                </p>
    </div>
    </div>
</body>

</html>
